{
    "dataset_reader":{
        "type":"conll2009"
    },
    "train_data_path": "/afs/inf.ed.ac.uk/user/s15/s1544871/Data/2009_conll_p2/data/CoNLL2009-ST-English/CoNLL2009-ST-English-train.txt",
    "validation_data_path": "/afs/inf.ed.ac.uk/user/s15/s1544871/Data/2009_conll_p2/data/CoNLL2009-ST-English/CoNLL2009-ST-English-development.txt",
    "test_data_path": "/afs/inf.ed.ac.uk/user/s15/s1544871/Data/2009_conll_p2/data/CoNLL2009-ST-English/CoNLL2009-ST-evaluation-English.txt",
    "model": {
      "type": "srl_graph_parser",
      "text_field_embedder": {
        "tokens": {
          "type": "embedding",
          "embedding_dim": 300,
          "pretrained_file": "/disk/scratch/s1544871/glove.840B.300d.txt",
          "trainable": true,
          "sparse": true
        }
      },
      "pos_tag_embedding":{
        "embedding_dim": 100,
        "vocab_namespace": "pos",
        "sparse": true
      },
      "encoder": {
        "type": "stacked_bidirectional_lstm",
        "input_size": 400,
        "hidden_size": 500,
        "num_layers": 3,
        "recurrent_dropout_probability": 0.3,
        "use_highway": true
      },
      "refine_representation_dim":200,
      "refiner": {
        "type": "srl_score_refiner",
        "iterations": 2,
        "dropout":0.3,
        "stright_through":false,
        "hidden_dim": 300,
        "detach":false,
        "initial_loss":true,
        "gumbel_t":1.0
      },
      "train_score":true,
      "tag_representation_dim": 200,
      "dropout": 0.3,
      "input_dropout": 0.3,
      "initializer": [
        [".*feedforward.*weight", {"type": "xavier_uniform"}],
        [".*feedforward.*bias", {"type": "zero"}],
        [".*tag_bilinear.*weight", {"type": "xavier_uniform"}],
        [".*tag_bilinear.*bias", {"type": "zero"}],
        [".*weight_ih.*", {"type": "xavier_uniform"}],
        [".*weight_hh.*", {"type": "orthogonal"}],
        [".*bias_ih.*", {"type": "zero"}],
        [".*bias_hh.*", {"type": "lstm_hidden_bias"}]]
    },

    "iterator": {
      "type": "bucket",
      "sorting_keys": [["tokens", "num_tokens"]],
      "batch_size" : 64
    },
    "evaluate_on_test": true,
    "trainer": {
      "num_epochs": 100,
      "grad_norm": 5.0,
      "patience": 50,
      "cuda_device": 2,
      "validation_metric": "+f1",
      "optimizer": {
        "type": "dense_sparse_adam",
        "betas": [0.9, 0.9]
      }
    }
  }

